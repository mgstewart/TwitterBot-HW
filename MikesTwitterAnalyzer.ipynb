{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import time\n",
    "import json\n",
    "import datetime as dt\n",
    "import csv\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as mpatches\n",
    "import seaborn as sns\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "# Twitter API Keys\n",
    "consumer_key = consumer_key\n",
    "consumer_secret = consumer_secret\n",
    "access_token = access_token\n",
    "access_token_secret = access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Credentials\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwitterBot():\n",
    "    acquiretarget()\n",
    "    searchfortweets(target_sn)\n",
    "    analyzeandplot(searchfortweets())\n",
    "    return print('Hi')\n",
    "\n",
    "def search_for_tweets(target_sn):\n",
    "    tweets_ago = 0\n",
    "    # Variable for holding the oldest tweet\n",
    "    oldest_tweet = None\n",
    "\n",
    "    # Variables for holding sentiments\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "    tweet_num_list = []\n",
    "\n",
    "    # Loop through 25 times\n",
    "    for x in range(2):\n",
    "\n",
    "        # Pull a page of tweets from the target_sn's timeline\n",
    "        public_tweets = api.user_timeline(target_sn, page=x, result_type=\"recent\")\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in public_tweets:\n",
    "\n",
    "            # Run Vader Analysis on each tweet\n",
    "            results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            compound = results[\"compound\"]\n",
    "            pos = results[\"pos\"]\n",
    "            neu = results[\"neu\"]\n",
    "            neg = results[\"neg\"]\n",
    "\n",
    "            # Add each value to the appropriate list\n",
    "            compound_list.append(compound)\n",
    "            positive_list.append(pos)\n",
    "            negative_list.append(neg)\n",
    "            neutral_list.append(neu)\n",
    "            \n",
    "            #Increment the num_tweets to count the tweets from most recent\n",
    "            tweet_num_list.append(tweets_ago)\n",
    "            tweets_ago -= 1\n",
    "                \n",
    "    # return the lists and target_sn for next method\n",
    "    return compound_list,positive_list,negative_list,neutral_list,tweet_num_list,target_sn\n",
    "\n",
    "def analyze_and_plot(compound_list,positive_list,negative_list,neutral_list,tweet_num_list,target_sn):\n",
    "    # Begin by constructing dataframe from tweet polarity lists\n",
    "    tweetdf = pd.DataFrame(compound_list,columns=['Compound Score'])\n",
    "    tweetdf['Positive Score'] = positive_list\n",
    "    tweetdf['Negative Score'] = negative_list\n",
    "    tweetdf['Neutral Score'] = neutral_list\n",
    "    # Rename index to tweets ago value\n",
    "    tweetdf.set_axis(tweet_num_list,axis=0,inplace=True)\n",
    "    # Define Seaborn style and generate plot\n",
    "    sns.set_style('darkgrid')\n",
    "    tweetplot = sns.tsplot(data=tweetdf['Compound Score'],time=tweetdf.index.values,condition=['Compound Score'])\n",
    "    # Label x and y axes\n",
    "    tweetplot.set_ylabel('Tweet Polarity')\n",
    "    tweetplot.set_xlabel('Tweets Ago')\n",
    "    # Create a patch for the legend to reflect the target_sn\n",
    "    user = mpatches.Patch(label=target_sn)\n",
    "    tweetplot.legend(handles=[user])\n",
    "    # Save the file to post later\n",
    "    plt.savefig((f'{target_sn}'),dpi=300)\n",
    "    return target_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_check_request():\n",
    "    #Declare local variables\n",
    "    recent_sn = ''\n",
    "    requester = ''\n",
    "    requesting_id = ''\n",
    "    list_of_targets = []\n",
    "    # Look at the most recent tweet on the bot's timeline and extract text content and author's sn\n",
    "    request_tweet = api.user_timeline('@AwayMikes',count=1,result_type='recent')\n",
    "    request_text = request_tweet[0]['text']\n",
    "    requester = '@'+request_tweet[0]['user']['screen_name']\n",
    "    requesting_id = request_tweet[0]['id_str']\n",
    "    #pprint(request_tweet)\n",
    "    # For simplicity sake, extract the last element that was split on @\n",
    "    # presumably this will be the target SN, if it is not, it will be handled later\n",
    "    _sn_start = request_text.rfind('@')\n",
    "    at_to_end = request_text[_sn_start:]\n",
    "    split_on_space = at_to_end.split(' ')\n",
    "    #recent_sn = split_on_space[0]\n",
    "    recent_sn = 'test1'\n",
    "    with open ('list_of_targets.csv',newline='') as csvfile:\n",
    "        target_reader = csv.reader(csvfile,delimiter=',')\n",
    "        for row in target_reader:\n",
    "            list_of_targets.append(row)\n",
    "    if recent_sn not in list_of_targets:\n",
    "        print(\"Something ain't right\")\n",
    "        print(recent_sn)\n",
    "        print(list_of_targets)\n",
    "    if recent_sn in list_of_targets:\n",
    "        print(\"BOYHOWDY I FOUND THIS ONE AGAIN!\")\n",
    "        api.update_with_media(f\"I'm sorry {requester}, {recent_sn} has already been analyzed. Here is the plot: \",\n",
    "                              requesting_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something ain't right\n",
      "test1\n",
      "[['@realDonaldTrump', 'test1']]\n"
     ]
    }
   ],
   "source": [
    "identify_check_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzeandplot(*searchfortweets('@RealDonaldTrump'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
